---
layout: post
title: HBase导出导入方案
categories: 大数据
tags: [大数据, hbase]
keywords: 大数据, hbase
description:
---
<meta name="referrer" content="no-referrer"/>

## 1. Export/Import
### A.Export
```bash
# hbase org.apache.hadoop.hbase.mapreduce.Export <tableName> <input_hdfs_path>
hbase org.apache.hadoop.hbase.mapreduce.Export member file:///tmp/member
```

### B.Import
```bash
# hbase org.apache.hadoop.hbase.mapreduce.Import <tableName> <input_hdfs_path>
hbase org.apache.hadoop.hbase.mapreduce.Import member file:///tmp/member
```

## 2. Snapshot

```bash
snapshot 'member', 'member_snapshot'
hbase org.apache.hadoop.hbase.snapshot.ExportSnapshot -snapshot 'member_snapshot' -copy-to file:///temp/member

hbase org.apache.hadoop.hbase.snapshot.tool.ExportSnapshot -snapshot MySnapshot -copy-to hdfs://srv2:8020/hbase
```
snapshot的应用场景和上面CopyTable描述差不多，我们这里主要考虑的是数据迁移部分。数据迁移主要有以下几个步骤：
### A.创建快照：
在原集群上，用snapshot命令创建快照，命令如下：

```bash
hbase> snapshot 'king_test', 'snapshot_king_test'
```

创建完快照后在/hbase根目录会产生一个目录：

```bash
/hbase/.hbase-snapshot/snapshot_king_test
```

#子目录下有如下几个文件

```bash
/hbase/.hbase-snapshot/ssnapshot_king_test/.snapshotinfo  
/hbase/.hbase-snapshot/ssnapshot_king_test/data.manifest
```

### B.数据迁移:
在上面创建好快照后，使用ExportSnapshot命令进行数据迁移，ExportSnapshot也是HDFS层的操作，本质还是利用MR进行迁移，这个过程主要涉及IO操作并消耗网络带宽，在迁移时要指定下map数和带宽，不然容易造成机房其它业务问题，如果是单独的MR集群，可以在MR集群上使用如下命令：

```bash
sudo su - hbase
```

以下命令需要hbase账户执行

```bash
hbase org.apache.hadoop.hbase.snapshot.ExportSnapshot \
-snapshot snapshot_king_test \
-copy-from hdfs://172.20.32.134:8020/hbase \
-copy-to hdfs://172.17.194.18:8020/hbase \
-mappers 20 \
-bandwidth 20
```


目标集群

```bash
clone_snapshot 'snapshot_king_test','king_test'
```

## 3. 暴力导入（实践成功）
1、从源HBase集群中复制出HBase数据库表到本地目录。

```bash
# 导出到本地目录上
hadoop fs -get /hbase/data/default/member /tmp

# 查看目录表
hadoop fs -ls /hbase/data/default
```

2、目标HBase导入（需关闭目标集群的hbase），将导出的数据传输到目标集群上

```bash
sudo -u hbase hadoop fs -put /tmp/member  /hbase/data/default/
hadoop fs -ls /hbase/data/default
```

3、修改复制过来的表目录文件的属主信息，重启HBase的所有组件，
4、登录HBaseshell已经可以通过list查看到迁移过来的表，但scan等操作会失败
5、修复.META.表

```bash
# 修复meta信息
sudo -u hbase hbase hbck -fixMeta

# 修复分区
sudo -u hbase hbase hbck -fixAssignments

# 查看该表的meta数据
scan 'hbase:meta'
```
## 常见问题

1.当hbase版本为0.98时，hadoop版本为2.5.2，导出数据会因为hbase版本低而报以下错误：
```
Exception in thread "main" java.lang.IllegalArgumentException: No enum constant org.apache.hadoop.mapreduce.JobCounter.MB_MILLIS_MAPS
```

解决办法：

**Hbase 0.98 使用的默认hadoop client 版本是2.2.0， 可以通过命令./hbase classpath 显示。**
**这是由于hbase 0.98使用的hadoop-client 与集群的hadoop版本不一致造成的。可能的几种解决方法**

1. 修改hbase/conf/hbase-env.sh
```bash
导入hadoop配置路径
export HBASE_CLASSPATH=/root/hadoop-2.5.2/etc/hadoop
```

2. 进入hbase/lib目录， 移走以hadoop- 开头的所有jar 包

```bash
mkdir /tmp/hbase_jar
mv lib/hadoop-* /tmp/hbase_jar
```

3. 加载classpath

```bash
hbase classpath
```

